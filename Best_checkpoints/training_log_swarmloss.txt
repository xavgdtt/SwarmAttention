step 0: train loss 4.1844 (main: 4.1835, form: 0.0176), val loss 4.1831 (main: 4.1822, form: 0.0181), time 64.30 s
step 200: train loss 1.7406 (main: 1.7389, form: 0.0337), val loss 1.8747 (main: 1.8730, form: 0.0355), time 273.16 s
step 400: train loss 1.5342 (main: 1.5328, form: 0.0263), val loss 1.7216 (main: 1.7203, form: 0.0267), time 482.05 s
step 600: train loss 1.4451 (main: 1.4439, form: 0.0247), val loss 1.6359 (main: 1.6346, form: 0.0251), time 691.01 s
step 800: train loss 1.3855 (main: 1.3843, form: 0.0234), val loss 1.5845 (main: 1.5833, form: 0.0239), time 899.83 s
step 1000: train loss 1.3402 (main: 1.3391, form: 0.0231), val loss 1.5497 (main: 1.5485, form: 0.0236), time 1109.28 s
step 1200: train loss 1.3021 (main: 1.3009, form: 0.0230), val loss 1.5234 (main: 1.5222, form: 0.0233), time 1318.57 s
step 1400: train loss 1.2704 (main: 1.2693, form: 0.0233), val loss 1.5092 (main: 1.5080, form: 0.0238), time 1527.99 s
step 1600: train loss 1.2441 (main: 1.2428, form: 0.0250), val loss 1.4986 (main: 1.4973, form: 0.0252), time 1836.33 s
step 1800: train loss 1.2232 (main: 1.2219, form: 0.0257), val loss 1.4850 (main: 1.4837, form: 0.0259), time 2159.42 s
step 2000: train loss 1.1926 (main: 1.1913, form: 0.0258), val loss 1.4843 (main: 1.4830, form: 0.0260), time 2475.65 s
step 2200: train loss 1.1720 (main: 1.1707, form: 0.0262), val loss 1.4657 (main: 1.4644, form: 0.0264), time 2802.02 s
step 2400: train loss 1.1502 (main: 1.1489, form: 0.0263), val loss 1.4680 (main: 1.4667, form: 0.0265), time 3118.68 s
step 2600: train loss 1.1313 (main: 1.1299, form: 0.0263), val loss 1.4652 (main: 1.4639, form: 0.0264), time 3423.06 s
step 2800: train loss 1.1178 (main: 1.1165, form: 0.0259), val loss 1.4765 (main: 1.4752, form: 0.0261), time 3752.09 s
step 2999: train loss 1.0951 (main: 1.0938, form: 0.0255), val loss 1.4769 (main: 1.4756, form: 0.0256), time 4086.79 s

Model Hyperparameters (config):
out_dir: swarmAtt_checkpoints
always_save_checkpoint: False
learning_rate: 0.0002
max_iters: 3000
weight_decay: 0.01
beta1: 0.9
beta2: 0.999
grad_clip: 0.0
dropout: 0.2
eval_iters: 200
eval_interval: 200
batch_size: 64
block_size: 256
n_embd: 256
n_head: 8
n_layer: 14
inf_steps: [1, 2, 3, 4, 1, 2, 3, 4]
head_steps: 1
formation_loss_weight: 0.05
formation_target_distance: 0
